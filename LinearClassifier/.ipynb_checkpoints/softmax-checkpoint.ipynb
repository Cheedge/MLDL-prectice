{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revolutionary-substitute",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0. nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-0eff16e97f8a>:3: RuntimeWarning: overflow encountered in exp\n",
      "  p = np.exp(f) / np.sum(np.exp(f))\n",
      "<ipython-input-1-0eff16e97f8a>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  p = np.exp(f) / np.sum(np.exp(f))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "f = np.array([123, 456, 789])\n",
    "p = np.exp(f) / np.sum(np.exp(f))\n",
    "print (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifty-score",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12998254 0.86904954 0.00096793]\n",
      "[2.04035515 0.14035515 6.94035515]\n"
     ]
    }
   ],
   "source": [
    "#f2 = [24.5, 164, 0.18]\n",
    "f1 = [3.2, 5.1, -1.7]\n",
    "f1 -= np.max(f1) # f becomes [-666, -333, 0]\n",
    "p = np.exp(f1) / np.sum(np.exp(f1)) # safe to do, gives the correct answer\n",
    "l = -np.log(p)\n",
    "print(p)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "public-ribbon",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0850, 0.0791, 0.0420],\n",
      "        [0.0678, 0.0930, 0.0518],\n",
      "        [0.0676, 0.0594, 0.0606],\n",
      "        [0.0843, 0.0703, 0.0810],\n",
      "        [0.0668, 0.0482, 0.0433]]) \n",
      "\n",
      "tensor([[0.0791, 0.0420, 0.0791, 0.0791, 0.0791],\n",
      "        [0.0930, 0.0518, 0.0930, 0.0930, 0.0930],\n",
      "        [0.0594, 0.0606, 0.0594, 0.0594, 0.0594],\n",
      "        [0.0703, 0.0810, 0.0703, 0.0703, 0.0703],\n",
      "        [0.0482, 0.0433, 0.0482, 0.0482, 0.0482]])\n",
      "tensor(1.6786)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "k = [1, 2, 1, 1, 1]\n",
    "x = torch.rand(5, 3)\n",
    "p0 = torch.exp(x) / torch.sum(torch.exp(x))\n",
    "pp = torch.exp(x[:, k]) / torch.sum(torch.exp(x))\n",
    "print(p0,'\\n')\n",
    "print(pp)\n",
    "loss = torch.sum(pp)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "monetary-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= tensor([[0.5543, 0.8334, 0.9069],\n",
      "        [0.3404, 0.5974, 0.1944],\n",
      "        [0.9386, 0.9261, 0.2960],\n",
      "        [0.8999, 0.1369, 0.8688]]) \n",
      "\n",
      "W= tensor([[0.0324, 0.7355, 0.1957, 0.3008, 0.3746],\n",
      "        [0.2613, 0.0940, 0.3617, 0.0796, 0.6467],\n",
      "        [0.7514, 0.1582, 0.6392, 0.9462, 0.5388]]) \n",
      "\n",
      "y= tensor([2, 0, 1, 3]) \n",
      "\n",
      "tensor([0.5867, 1.0947, 1.6583])\n",
      "tensor([1.2899, 0.9274, 1.0651])\n",
      "tensor([0.7501, 1.1951, 1.5461])\n",
      "tensor([0.8552, 0.9130, 1.8531])\n",
      "tensor([0.9289, 1.4801, 1.4457])\n"
     ]
    }
   ],
   "source": [
    "# vector-wise\n",
    "import numpy as np\n",
    "import torch\n",
    "reg = 0.01\n",
    "X = torch.rand(4, 3) # N * D = 4 * 3\n",
    "W = torch.rand(3, 5) # D * C = 3 * 5\n",
    "#y = torch.randint(4, (4,)) # N = 4\n",
    "y = torch.randperm(4)\n",
    "num_train = X.shape[0]\n",
    "num_classes = W.shape[1]\n",
    "print('X=', X, '\\n')\n",
    "print('W=', W, '\\n')\n",
    "print('y=', y, '\\n')\n",
    "\n",
    "for j in range(5):\n",
    "    W[:, j] += X[0]\n",
    "    print(W[:, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "short-steps",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9458, -0.4032, -0.2765, -0.6470, -0.4572],\n",
      "        [-0.7259, -0.7193, -0.5570, -0.7627, -0.6967],\n",
      "        [-0.6899, -0.3192, -0.0485, -0.4018, -0.2511],\n",
      "        [-0.7217, -0.1981,  0.0000, -0.4174, -0.2181]]) \n",
      "\n",
      "tensor([-0.2765, -0.7193, -0.4018, -0.7217]) \n",
      "\n",
      "tensor([-2.7298, -3.4616, -1.7105, -1.5554])\n"
     ]
    }
   ],
   "source": [
    "s = X.mm(W)\n",
    "pp = s[:, y]\n",
    "#print(score_0-torch.max(score_0))\n",
    "print(score,'\\n')\n",
    "print(score[torch.arange(num_train),y],'\\n')\n",
    "#print(score[torch.arange(num_train), :])\n",
    "print(torch.sum(score, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "extra-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0 = tensor([[ 0.1855,  0.1392, -0.8005,  0.2208,  0.2550],\n",
      "        [-0.8182,  0.1862,  0.1997,  0.1856,  0.2467],\n",
      "        [ 0.1508, -0.7903,  0.1867,  0.1737,  0.2791],\n",
      "        [ 0.1716,  0.1886,  0.1828, -0.7476,  0.2046]]) \n",
      " p = tensor([0.1995, 0.1818, 0.2097, 0.2524])\n",
      "dW_vec = tensor([[ 0.1204, -0.4315, -0.0361, -0.3241,  0.6714],\n",
      "        [-0.1710, -0.4788, -0.3500,  0.3535,  0.6464],\n",
      "        [ 0.2030,  0.0923, -0.4731, -0.3617,  0.5396]])\n",
      "*******************************************************************\n",
      "score = tensor([[-0.3181, -0.6057, -0.2456, -0.1440,  0.0000],\n",
      "        [-1.8836, -1.8595, -1.7898, -1.8629, -1.5782],\n",
      "        [-1.0042, -0.6747, -0.7911, -0.8629, -0.3890],\n",
      "        [-0.9411, -0.8466, -0.8778, -0.5552, -0.7651]]) \n",
      "\n",
      "dW =  tensor([[ 0.0418, -0.0821,  0.0060, -0.0639,  0.1864],\n",
      "        [-0.0209, -0.1012, -0.0636,  0.1066,  0.1912],\n",
      "        [ 0.0839,  0.0444, -0.0874, -0.0534,  0.1638]]) \n",
      "\n",
      "p = tensor([0.1995, 0.1818, 0.2097, 0.2524])\n",
      "loss = tensor(1.7887)\n"
     ]
    }
   ],
   "source": [
    "# vector-wise\n",
    "loss_vec = 0\n",
    "dW_vec = torch.zeros_like(W)\n",
    "score = X.mm(W) # N * C = 4 * 5\n",
    "b = torch.arange(num_train)\n",
    "score[b, :] -= torch.max(score[b, :])\n",
    "#score_t = W.t().mm(X.t()) # C * N = 5 * 4\n",
    "\n",
    "#print(torch.exp(score[b, :]), '\\n', torch.sum(torch.exp(score), axis = 1), '\\n')\n",
    "p0 = torch.exp(score[b, :].t()) / torch.sum(torch.exp(score), axis = 1) # N * C = 4 * 5\n",
    "p = torch.exp(score[b, y]) / torch.sum(torch.exp(score), axis = 1) # N * C = 4 * 5\n",
    "p0 = p0.t() # N * C\n",
    "#print(p0, '\\n')\n",
    "p0[b, y] += -1 #+ (torch.exp(score[b, y]) / torch.sum(torch.exp(score), axis = 1))\n",
    "print('p0 =', p0, '\\n', 'p =', p)\n",
    "\n",
    "# refer to: https://github.com/jariasf/CS231n/blob/master/assignment1/cs231n/classifiers/softmax.py\n",
    "#sum_exp_scores = np.exp(scores).sum(axis=1, keepdims=True)\n",
    "#softmax_matrix = np.exp(scores)/sum_exp_scores\n",
    "\n",
    "\n",
    "loss_vec = torch.sum(-torch.log(p))\n",
    "loss_vec /= num_train\n",
    "loss_vec += torch.sum(W * W) * reg\n",
    "\n",
    "dW_vec = X.t().mm(p0)\n",
    "#p0X = X.t().mm(p0)\n",
    "#print('p0X =', p0X, '\\n', 'W =', W)\n",
    "#dW_vec_row = torch.sum(p0X, axis=0)\n",
    "#print(\"dW_vec_row =\", dW_vec_row)\n",
    "#\n",
    "#dW_vec = torch.unsqueeze(dW_vec_row, 1).expand(-1, W.shape[1]).clone() # refer to https://stackoverflow.com/questions/59905234/runtimeerror-with-copy-and-expand-unsupported-operation-more-than-one-el\n",
    "print('dW_vec =', dW_vec)\n",
    "#dW_vec = dW_vec + 2 * reg * W\n",
    "dW_vec /= num_train\n",
    "dW_vec += 2 * reg * W\n",
    "\n",
    "\n",
    "print('*******************************************************************')\n",
    "print('score =', score, '\\n')\n",
    "#print('p0=', p0, '\\n')\n",
    "print('dW = ', dW_vec, '\\n')\n",
    "print('p =', p)\n",
    "#print('l=', l, '\\n')\n",
    "print(\"loss =\", loss_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "vocational-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "p = tensor(0.1995)\n",
      "tensor(0)\n",
      "p = tensor(0.1818)\n",
      "tensor(1)\n",
      "p = tensor(0.2097)\n",
      "tensor(3)\n",
      "p = tensor(0.2524)\n",
      "score = tensor([-0.3859, -0.2914, -0.3226,  0.0000, -0.2099]) \n",
      "\n",
      "dW =  tensor([[ 0.0418, -0.0821,  0.0060, -0.0639,  0.1864],\n",
      "        [-0.0209, -0.1012, -0.0636,  0.1066,  0.1912],\n",
      "        [ 0.0839,  0.0444, -0.0874, -0.0534,  0.1638]]) \n",
      "\n",
      "p = tensor(0.2524)\n",
      "loss = tensor(1.7887)\n"
     ]
    }
   ],
   "source": [
    "# element-wise softmax loss\n",
    "loss_element = 0\n",
    "dW_element = torch.zeros_like(W)\n",
    "#num_train = X.shape[0] # num batch\n",
    "#num_classes = W.shape[1]\n",
    "for i in range(num_train):\n",
    "    score_element = W.t().mv(X[i]) # score of one batch: C * 1 = 5 * 1\n",
    "    score_element -= torch.max(score_element)\n",
    "    numerator = torch.exp(score_element[y[i]])\n",
    "    denominator = torch.sum(torch.exp(score_element))\n",
    "    p0_element = torch.exp(score_element) / torch.sum(torch.exp(score_element))\n",
    "    print(y[i])\n",
    "    p_element = torch.exp(score_element[y[i]]) / torch.sum(torch.exp(score_element))\n",
    "    print('p =', p_element)\n",
    "    #print('p0 =', p0_element)\n",
    "    loss_element += -torch.log(p_element)\n",
    "    for j in range(num_classes):\n",
    "        if (j == y[i]):\n",
    "#            dW_element[:, y[i]] += X[i, :] * (-1 + numerator / denominator)\n",
    "            dW_element[:, j] += X[i, :] * (-1)\n",
    "        dW_element[:, j] += X[i, :] * torch.exp(score_element[j]) / denominator\n",
    "loss_element /= num_train    \n",
    "loss_element += torch.sum(W * W) * reg\n",
    "dW_element /= num_train\n",
    "dW_element += 2 * reg * W\n",
    "\n",
    "print('score =', score_element, '\\n')\n",
    "#print('p0=', p0, '\\n')\n",
    "print('dW = ', dW_element, '\\n')\n",
    "print('p =', p_element)\n",
    "#print('l=', l, '\\n')\n",
    "print(\"loss =\", loss_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "atomic-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "p = tensor(0.1995)\n",
      "tensor(0)\n",
      "p = tensor(0.1818)\n",
      "tensor(1)\n",
      "p = tensor(0.2097)\n",
      "tensor(3)\n",
      "p = tensor(0.2524)\n",
      "score = tensor([-0.3859, -0.2914, -0.3226,  0.0000, -0.2099]) \n",
      "\n",
      "dW =  tensor([[ 0.0418, -0.0821,  0.0060, -0.0639,  0.1864],\n",
      "        [-0.0209, -0.1012, -0.0636,  0.1066,  0.1912],\n",
      "        [ 0.0839,  0.0444, -0.0874, -0.0534,  0.1638]]) \n",
      "\n",
      "p = tensor(0.2524)\n",
      "loss = tensor(1.7887)\n"
     ]
    }
   ],
   "source": [
    "# element-wise softmax loss\n",
    "loss_element = 0\n",
    "dW_element = torch.zeros_like(W)\n",
    "#num_train = X.shape[0] # num batch\n",
    "#num_classes = W.shape[1]\n",
    "for i in range(num_train):\n",
    "    score_element = W.t().mv(X[i]) # score of one batch: C * 1 = 5 * 1\n",
    "    score_element -= torch.max(score_element)\n",
    "    numerator = torch.exp(score_element[y[i]])\n",
    "    denominator = torch.sum(torch.exp(score_element))\n",
    "    p0_element = torch.exp(score_element) / torch.sum(torch.exp(score_element))\n",
    "    print(y[i])\n",
    "    p_element = torch.exp(score_element[y[i]]) / torch.sum(torch.exp(score_element))\n",
    "    print('p =', p_element)\n",
    "    #print('p0 =', p0_element)\n",
    "    loss_element += -torch.log(p_element)\n",
    "    for j in range(num_classes):\n",
    "        \n",
    "        dW_element[:, j] += X[i, :] * torch.exp(score_element[j]) / denominator\n",
    "    dW_element[:, y[i]] -= X[i, :]\n",
    "loss_element /= num_train    \n",
    "loss_element += torch.sum(W * W) * reg\n",
    "dW_element /= num_train\n",
    "dW_element += 2 * reg * W\n",
    "\n",
    "print('score =', score_element, '\\n')\n",
    "#print('p0=', p0, '\\n')\n",
    "print('dW = ', dW_element, '\\n')\n",
    "print('p =', p_element)\n",
    "#print('l=', l, '\\n')\n",
    "print(\"loss =\", loss_element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
